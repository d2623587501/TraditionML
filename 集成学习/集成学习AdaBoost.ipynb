{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 声明：内容为学习笔记，仅供学习交流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Boost\n",
    "\n",
    "“装袋”（bagging）和“提升”（boost）是构建组合模型的两种最主要的方法，所谓的组合模型是由多个基本模型构成的模型，组合模型的预测效果往往比任意一个基本模型的效果都要好。\n",
    "\n",
    "- 装袋：每个基本模型由从总体样本中随机抽样得到的不同数据集进行训练得到，通过重抽样得到不同训练数据集的过程称为装袋。\n",
    "\n",
    "- 提升：每个基本模型训练时的数据集采用不同权重，针对上一个基本模型分类错误的样本增加权重，使得新的模型重点关注误分类样本\n",
    "\n",
    "### AdaBoost\n",
    "\n",
    "AdaBoost是AdaptiveBoost的缩写，表明该算法是具有适应性的提升算法。\n",
    "\n",
    "算法的步骤如下：\n",
    "\n",
    "1）给每个训练样本（x1,x2,….,xN）分配权重，初始权重$w_{1}$均为1/N。\n",
    "\n",
    "2）针对带有权值的样本进行训练，得到模型$G_m$（初始模型为G1）。\n",
    "\n",
    "3）计算模型$G_m$的误分率$e_m=\\sum_{i=1}^Nw_iI(y_i\\not= G_m(x_i))$\n",
    "\n",
    "4）计算模型$G_m$的系数$\\alpha_m=0.5\\log[(1-e_m)/e_m]$\n",
    "\n",
    "5）根据误分率e和当前权重向量$w_m$更新权重向量$w_{m+1}$。\n",
    "\n",
    "6）计算组合模型$f(x)=\\sum_{m=1}^M\\alpha_mG_m(x_i)$的误分率。\n",
    "\n",
    "7）当组合模型的误分率或迭代次数低于一定阈值，停止迭代；否则，回到步骤2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i,-1] == 0:\n",
    "            data[i,-1] = -1\n",
    "    # print(data)\n",
    "    return data[:,:2], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3341ce0b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----\n",
    "\n",
    "### AdaBoost in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0):\n",
    "        self.clf_num = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def init_args(self, datasets, labels):\n",
    "        \n",
    "        self.X = datasets\n",
    "        self.Y = labels\n",
    "        self.M, self.N = datasets.shape\n",
    "        \n",
    "        # 弱分类器数目和集合\n",
    "        self.clf_sets = []\n",
    "        \n",
    "        # 初始化weights\n",
    "        self.weights = [1.0/self.M]*self.M\n",
    "        \n",
    "        # G(x)系数 alpha\n",
    "        self.alpha = []\n",
    "        \n",
    "    def _G(self, features, labels, weights):\n",
    "        m = len(features)\n",
    "        error = 100000.0 # 无穷大\n",
    "        best_v = 0.0\n",
    "        # 单维features\n",
    "        features_min = min(features)\n",
    "        features_max = max(features)\n",
    "        n_step = (features_max - features_min + self.learning_rate) // self.learning_rate\n",
    "        # print('n_step:{}'.format(n_step))\n",
    "        direct, compare_array = None, None\n",
    "        for i in range(1, int(n_step)):\n",
    "            v = features_min + self.learning_rate * i\n",
    "            \n",
    "            if v not in features:\n",
    "                # 误分类计算\n",
    "                compare_array_positive = np.array([1 if features[k] > v else -1 for k in range(m)])\n",
    "                weight_error_positive = sum([weights[k] for k in range(m) if compare_array_positive[k] != labels[k]])\n",
    "                \n",
    "                compare_array_nagetive = np.array([-1 if features[k] > v else 1 for k in range(m)])\n",
    "                weight_error_nagetive = sum([weights[k] for k in range(m) if compare_array_nagetive[k] != labels[k]])\n",
    "\n",
    "                if weight_error_positive < weight_error_nagetive:\n",
    "                    weight_error = weight_error_positive\n",
    "                    _compare_array = compare_array_positive\n",
    "                    direct = 'positive'\n",
    "                else:\n",
    "                    weight_error = weight_error_nagetive\n",
    "                    _compare_array = compare_array_nagetive\n",
    "                    direct = 'nagetive'\n",
    "                    \n",
    "                # print('v:{} error:{}'.format(v, weight_error))\n",
    "                if weight_error < error:\n",
    "                    error = weight_error\n",
    "                    compare_array = _compare_array\n",
    "                    best_v = v\n",
    "        return best_v, direct, error, compare_array\n",
    "        \n",
    "    # 计算alpha\n",
    "    def _alpha(self, error):\n",
    "        return 0.5 * np.log((1-error)/error)\n",
    "    \n",
    "    # 规范化因子\n",
    "    def _Z(self, weights, a, clf):\n",
    "        return sum([weights[i]*np.exp(-1*a*self.Y[i]*clf[i]) for i in range(self.M)])\n",
    "        \n",
    "    # 权值更新\n",
    "    def _w(self, a, clf, Z):\n",
    "        for i in range(self.M):\n",
    "            self.weights[i] = self.weights[i]*np.exp(-1*a*self.Y[i]*clf[i])/ Z\n",
    "    \n",
    "    # G(x)的线性组合\n",
    "    def _f(self, alpha, clf_sets):\n",
    "        pass\n",
    "    \n",
    "    def G(self, x, v, direct):\n",
    "        if direct == 'positive':\n",
    "            return 1 if x > v else -1 \n",
    "        else:\n",
    "            return -1 if x > v else 1 \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.init_args(X, y)\n",
    "        \n",
    "        for epoch in range(self.clf_num):\n",
    "            best_clf_error, best_v, clf_result = 100000, None, None\n",
    "            # 根据特征维度, 选择误差最小的\n",
    "            for j in range(self.N):\n",
    "                features = self.X[:, j]\n",
    "                # 分类阈值，分类误差，分类结果\n",
    "                v, direct, error, compare_array = self._G(features, self.Y, self.weights)\n",
    "                \n",
    "                if error < best_clf_error:\n",
    "                    best_clf_error = error\n",
    "                    best_v = v\n",
    "                    final_direct = direct\n",
    "                    clf_result = compare_array\n",
    "                    axis = j\n",
    "                    \n",
    "                # print('epoch:{}/{} feature:{} error:{} v:{}'.format(epoch, self.clf_num, j, error, best_v))\n",
    "                if best_clf_error == 0:\n",
    "                    break\n",
    "                \n",
    "            # 计算G(x)系数a\n",
    "            a = self._alpha(best_clf_error)\n",
    "            self.alpha.append(a)\n",
    "            # 记录分类器\n",
    "            self.clf_sets.append((axis, best_v, final_direct))\n",
    "            # 规范化因子\n",
    "            Z = self._Z(self.weights, a, clf_result)\n",
    "            # 权值更新\n",
    "            self._w(a, clf_result, Z)\n",
    "            \n",
    "#             print('classifier:{}/{} error:{:.3f} v:{} direct:{} a:{:.5f}'.format(epoch+1, self.clf_num, error, best_v, final_direct, a))\n",
    "#             print('weight:{}'.format(self.weights))\n",
    "#             print('\\n')\n",
    "    \n",
    "    def predict(self, feature):\n",
    "        result = 0.0\n",
    "        for i in range(len(self.clf_sets)):\n",
    "            axis, clf_v, direct = self.clf_sets[i]\n",
    "            f_input = feature[axis]\n",
    "            result += self.alpha[i] * self.G(f_input, clf_v, direct)\n",
    "        # sign\n",
    "        return 1 if result > 0 else -1\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            feature = X_test[i]\n",
    "            if self.predict(feature) == y_test[i]:\n",
    "                right_count += 1\n",
    "        \n",
    "        return right_count / len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 例8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(10, 1)\n",
    "y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = AdaBoost(n_estimators=3, learning_rate=0.5)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoost(n_estimators=10, learning_rate=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score:67.273%\n"
     ]
    }
   ],
   "source": [
    "# 100次结果\n",
    "result = []\n",
    "for i in range(1, 101):\n",
    "    X, y = create_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf = AdaBoost(n_estimators=100, learning_rate=0.2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    r = clf.score(X_test, y_test)\n",
    "    # print('{}/100 score：{}'.format(i, r))\n",
    "    result.append(r)\n",
    "\n",
    "print('average score:{:.3f}%'.format(sum(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-----\n",
    "# sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "- algorithm：这个参数只有AdaBoostClassifier有。主要原因是scikit-learn实现了两种Adaboost分类算法，SAMME和SAMME.R。两者的主要区别是弱学习器权重的度量，SAMME使用了和我们的原理篇里二元分类Adaboost算法的扩展，即用对样本集分类效果作为弱学习器权重，而SAMME.R使用了对样本集分类的预测概率大小来作为弱学习器权重。由于SAMME.R使用了概率度量的连续值，迭代一般比SAMME快，因此AdaBoostClassifier的默认算法algorithm的值也是SAMME.R。我们一般使用默认的SAMME.R就够了，但是要注意的是使用了SAMME.R， 则弱分类学习器参数base_estimator必须限制使用支持概率预测的分类器。SAMME算法则没有这个限制。\n",
    "\n",
    "- n_estimators： AdaBoostClassifier和AdaBoostRegressor都有，就是我们的弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是50。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。\n",
    "\n",
    "-  learning_rate:  AdaBoostClassifier和AdaBoostRegressor都有，即每个弱学习器的权重缩减系数ν\n",
    "\n",
    "- base_estimator：AdaBoostClassifier和AdaBoostRegressor都有，即我们的弱分类学习器或者弱回归学习器。理论上可以选择任何一个分类或者回归学习器，不过需要支持样本权重。我们常用的一般是CART决策树或者神经网络MLP。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.5,\n",
       "                   n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393939393939394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
